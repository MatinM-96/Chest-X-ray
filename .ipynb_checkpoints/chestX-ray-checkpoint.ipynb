{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c41317d-6ddc-4981-ad21-642cfdce4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /home/matinm/chest X-ray/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96ee1714-b491-466d-b69f-e317550981d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin https://github.com/MatinM-96/Chest-X-ray.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dca9ae7-db00-4f22-bd7c-c2cc191afaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4468acd-b97b-4f47-8036-59de43990af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter cell, the leading \"!\" runs a shell command\n",
    "!pip -q install kaggle\n",
    "\n",
    "# Upload your Kaggle API key (kaggle.json) to the notebook, or paste below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0300f9e2-c218-47ca-b8f3-6591cfc5473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'kaggle.json': No such file or directory\n",
      "-rw------- 1 matinm users 64 Aug 18 09:12 /home/matinm/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -lah ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1a8bdfb-610c-4861-9a8b-64a4d5f67baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28d0bbd3-89d5-4968-a3a4-f7cf9e1185b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'kaggle.json': No such file or directory\n",
      "ls: cannot access '/home/matinm/.kaggle/kaggle.json#': No such file or directory\n",
      "ls: cannot access 'Install': No such file or directory\n",
      "ls: cannot access 'dependencies': No such file or directory\n",
      "ls: cannot access 'as': No such file or directory\n",
      "ls: cannot access 'needed:': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151/1100528057.py:12: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the latest version\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mKaggleDatasetAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPANDAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnih-chest-xrays/data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide any additional arguments like \u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sql_query or pandas_kwargs. See the \u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# documenation for more information:\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 records:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:176\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(\n\u001b[1;32m    164\u001b[0m     adapter: KaggleDatasetAdapter,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# In the form of {owner_slug}/{dataset_slug} or {owner_slug}/{dataset_slug}/versions/{version_number}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     hf_kwargs: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    172\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_dataset is deprecated and will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:141\u001b[0m, in \u001b[0;36mdataset_load\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs, polars_frame_type, polars_kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPANDAS:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datasets\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pandas_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPOLARS:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_datasets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:86\u001b[0m, in \u001b[0;36mload_pandas_dataset\u001b[0;34m(handle, path, pandas_kwargs, sql_query)\u001b[0m\n\u001b[1;32m     84\u001b[0m pandas_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m pandas_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pandas_kwargs\n\u001b[1;32m     85\u001b[0m file_extension \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(path)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 86\u001b[0m read_function \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_read_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Now that everything has been validated, we can start downloading and processing\u001b[39;00m\n\u001b[1;32m     89\u001b[0m filepath \u001b[38;5;241m=\u001b[39m dataset_download(handle, path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:108\u001b[0m, in \u001b[0;36m_validate_read_function\u001b[0;34m(file_extension, sql_query)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extension \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION:\n\u001b[1;32m    104\u001b[0m     extension_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file extension: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_extension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported file extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_READ_FUNCTIONS_BY_EXTENSION\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(extension_error_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    110\u001b[0m read_function \u001b[38;5;241m=\u001b[39m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION[file_extension]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_function \u001b[38;5;129;01mis\u001b[39;00m wrapped_read_sql_query \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sql_query:\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt"
     ]
    }
   ],
   "source": [
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -lah ~/.kaggle/kaggle.json# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0370c94b-9ec8-4aa8-8634-c51ef825f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151/2012154759.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the latest version\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mKaggleDatasetAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPANDAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnih-chest-xrays/data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide any additional arguments like \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sql_query or pandas_kwargs. See the \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# documenation for more information:\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 records:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:176\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(\n\u001b[1;32m    164\u001b[0m     adapter: KaggleDatasetAdapter,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# In the form of {owner_slug}/{dataset_slug} or {owner_slug}/{dataset_slug}/versions/{version_number}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     hf_kwargs: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    172\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_dataset is deprecated and will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:141\u001b[0m, in \u001b[0;36mdataset_load\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs, polars_frame_type, polars_kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPANDAS:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datasets\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pandas_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPOLARS:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_datasets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:86\u001b[0m, in \u001b[0;36mload_pandas_dataset\u001b[0;34m(handle, path, pandas_kwargs, sql_query)\u001b[0m\n\u001b[1;32m     84\u001b[0m pandas_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m pandas_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pandas_kwargs\n\u001b[1;32m     85\u001b[0m file_extension \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(path)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 86\u001b[0m read_function \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_read_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Now that everything has been validated, we can start downloading and processing\u001b[39;00m\n\u001b[1;32m     89\u001b[0m filepath \u001b[38;5;241m=\u001b[39m dataset_download(handle, path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:108\u001b[0m, in \u001b[0;36m_validate_read_function\u001b[0;34m(file_extension, sql_query)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extension \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION:\n\u001b[1;32m    104\u001b[0m     extension_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file extension: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_extension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported file extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_READ_FUNCTIONS_BY_EXTENSION\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(extension_error_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    110\u001b[0m read_function \u001b[38;5;241m=\u001b[39m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION[file_extension]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_function \u001b[38;5;129;01mis\u001b[39;00m wrapped_read_sql_query \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sql_query:\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "195b5000-a3b3-4ffb-82c6-2558750a85f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: kagglehub in /home/matinm/.local/lib/python3.10/site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28d265da-8bca-444a-aa71-7874a0123a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151/2012154759.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the latest version\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m  \u001b[49m\u001b[43mKaggleDatasetAdapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPANDAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnih-chest-xrays/data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Provide any additional arguments like \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# sql_query or pandas_kwargs. See the \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# documenation for more information:\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst 5 records:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:176\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(\n\u001b[1;32m    164\u001b[0m     adapter: KaggleDatasetAdapter,\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# In the form of {owner_slug}/{dataset_slug} or {owner_slug}/{dataset_slug}/versions/{version_number}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     hf_kwargs: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    172\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:  \u001b[38;5;66;03m# noqa: ANN401\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_dataset is deprecated and will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43madapter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/datasets.py:141\u001b[0m, in \u001b[0;36mdataset_load\u001b[0;34m(adapter, handle, path, pandas_kwargs, sql_query, hf_kwargs, polars_frame_type, polars_kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPANDAS:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datasets\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_pandas_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_query\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m adapter \u001b[38;5;129;01mis\u001b[39;00m KaggleDatasetAdapter\u001b[38;5;241m.\u001b[39mPOLARS:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolars_datasets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:86\u001b[0m, in \u001b[0;36mload_pandas_dataset\u001b[0;34m(handle, path, pandas_kwargs, sql_query)\u001b[0m\n\u001b[1;32m     84\u001b[0m pandas_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m pandas_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pandas_kwargs\n\u001b[1;32m     85\u001b[0m file_extension \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(path)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 86\u001b[0m read_function \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_read_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_extension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msql_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Now that everything has been validated, we can start downloading and processing\u001b[39;00m\n\u001b[1;32m     89\u001b[0m filepath \u001b[38;5;241m=\u001b[39m dataset_download(handle, path)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kagglehub/pandas_datasets.py:108\u001b[0m, in \u001b[0;36m_validate_read_function\u001b[0;34m(file_extension, sql_query)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_extension \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION:\n\u001b[1;32m    104\u001b[0m     extension_error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file extension: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_extension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported file extensions are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_READ_FUNCTIONS_BY_EXTENSION\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m     )\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(extension_error_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    110\u001b[0m read_function \u001b[38;5;241m=\u001b[39m SUPPORTED_READ_FUNCTIONS_BY_EXTENSION[file_extension]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_function \u001b[38;5;129;01mis\u001b[39;00m wrapped_read_sql_query \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sql_query:\n",
      "\u001b[0;31mValueError\u001b[0m: Unsupported file extension: ''. Supported file extensions are: .csv, .tsv, .json, .jsonl, .xml, .parquet, .feather, .sqlite, .sqlite3, .db, .db3, .s3db, .dl3, .xls, .xlsx, .xlsm, .xlsb, .odf, .ods, .odt"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d3e6beb-1f21-4261-9848-d91beb67adb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './kaggle.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./kaggle.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:   \u001b[38;5;66;03m# change to \"./kaggle.json\" if it's beside the notebook\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     creds \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKAGGLE_USERNAME\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m creds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './kaggle.json'"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "with open(\"./kaggle.json\", \"r\") as f:   # change to \"./kaggle.json\" if it's beside the notebook\n",
    "    creds = json.load(f)\n",
    "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
    "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abd87766-3415-4d61-b3c9-1f16481ee299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151/537646008.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112120, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Index</th>\n",
       "      <th>Finding Labels</th>\n",
       "      <th>Follow-up #</th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Patient Age</th>\n",
       "      <th>Patient Gender</th>\n",
       "      <th>View Position</th>\n",
       "      <th>OriginalImage[Width</th>\n",
       "      <th>Height]</th>\n",
       "      <th>OriginalImagePixelSpacing[x</th>\n",
       "      <th>y]</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000001_000.png</td>\n",
       "      <td>Cardiomegaly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2682</td>\n",
       "      <td>2749</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000001_001.png</td>\n",
       "      <td>Cardiomegaly|Emphysema</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2894</td>\n",
       "      <td>2729</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000001_002.png</td>\n",
       "      <td>Cardiomegaly|Effusion</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000002_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>M</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000003_000.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00000003_001.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00000003_002.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00000003_003.png</td>\n",
       "      <td>Hernia|Infiltration</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2698</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00000003_004.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00000003_005.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2686</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00000003_006.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2992</td>\n",
       "      <td>2991</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00000003_007.png</td>\n",
       "      <td>Hernia</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2582</td>\n",
       "      <td>2905</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00000004_000.png</td>\n",
       "      <td>Mass|Nodule</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>M</td>\n",
       "      <td>AP</td>\n",
       "      <td>2500</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00000005_000.png</td>\n",
       "      <td>No Finding</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>PA</td>\n",
       "      <td>2048</td>\n",
       "      <td>2500</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.168</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
       "0   00000001_000.png            Cardiomegaly            0           1   \n",
       "1   00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
       "2   00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
       "3   00000002_000.png              No Finding            0           2   \n",
       "4   00000003_000.png                  Hernia            0           3   \n",
       "5   00000003_001.png                  Hernia            1           3   \n",
       "6   00000003_002.png                  Hernia            2           3   \n",
       "7   00000003_003.png     Hernia|Infiltration            3           3   \n",
       "8   00000003_004.png                  Hernia            4           3   \n",
       "9   00000003_005.png                  Hernia            5           3   \n",
       "10  00000003_006.png                  Hernia            6           3   \n",
       "11  00000003_007.png                  Hernia            7           3   \n",
       "12  00000004_000.png             Mass|Nodule            0           4   \n",
       "13  00000005_000.png              No Finding            0           5   \n",
       "\n",
       "    Patient Age Patient Gender View Position  OriginalImage[Width  Height]  \\\n",
       "0            58              M            PA                 2682     2749   \n",
       "1            58              M            PA                 2894     2729   \n",
       "2            58              M            PA                 2500     2048   \n",
       "3            81              M            PA                 2500     2048   \n",
       "4            81              F            PA                 2582     2991   \n",
       "5            74              F            PA                 2500     2048   \n",
       "6            75              F            PA                 2048     2500   \n",
       "7            76              F            PA                 2698     2991   \n",
       "8            77              F            PA                 2500     2048   \n",
       "9            78              F            PA                 2686     2991   \n",
       "10           79              F            PA                 2992     2991   \n",
       "11           80              F            PA                 2582     2905   \n",
       "12           82              M            AP                 2500     2048   \n",
       "13           69              F            PA                 2048     2500   \n",
       "\n",
       "    OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n",
       "0                         0.143  0.143          NaN  \n",
       "1                         0.143  0.143          NaN  \n",
       "2                         0.168  0.168          NaN  \n",
       "3                         0.171  0.171          NaN  \n",
       "4                         0.143  0.143          NaN  \n",
       "5                         0.168  0.168          NaN  \n",
       "6                         0.168  0.168          NaN  \n",
       "7                         0.143  0.143          NaN  \n",
       "8                         0.168  0.168          NaN  \n",
       "9                         0.143  0.143          NaN  \n",
       "10                        0.143  0.143          NaN  \n",
       "11                        0.143  0.143          NaN  \n",
       "12                        0.168  0.168          NaN  \n",
       "13                        0.168  0.168          NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install kagglehub[pandas-datasets] pandas\n",
    "\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Pick a file from the dataset to read directly into pandas:\n",
    "file_path = \"Data_Entry_2017.csv\"   # NIH Chest X-rays: labels/metadata CSV\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"nih-chest-xrays/data\",\n",
    "    file_path,\n",
    "    pandas_kwargs={\"low_memory\": False}  # optional pandas args\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head(14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb44bac6-a75a-422d-b0c3-ec8887c26da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y: (112120, 14)\n",
      "Positives per class: {'Atelectasis': 11559, 'Cardiomegaly': 2776, 'Effusion': 13317, 'Infiltration': 19894, 'Mass': 5782, 'Nodule': 6331, 'Pneumonia': 1431, 'Pneumothorax': 5302, 'Consolidation': 4667, 'Edema': 2303, 'Emphysema': 2516, 'Fibrosis': 1686, 'Pleural_Thickening': 3385, 'Hernia': 227}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88697, 11794, 11629)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NIH canonical 14 labels\n",
    "LABELS = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','Nodule',\n",
    "    'Pneumonia','Pneumothorax','Consolidation','Edema','Emphysema',\n",
    "    'Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "\n",
    "\n",
    "# Convert Finding Labels to multi-hot vectors\n",
    "def to_multi_hot(lbl_str):\n",
    "    y = np.zeros(len(LABELS), dtype=np.float32)\n",
    "    if isinstance(lbl_str, str) and lbl_str != \"No Finding\":\n",
    "        for t in lbl_str.split(\"|\"):\n",
    "            if t in LABELS:\n",
    "                y[LABELS.index(t)] = 1.0\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Make an empty list\n",
    "all_labels = []\n",
    "\n",
    "# 2. Loop over each row in the DataFrame\n",
    "for label_str in df[\"Finding Labels\"].astype(str):\n",
    "    # Convert string like \"Cardiomegaly|Effusion\" to a multi-hot vector\n",
    "    y = to_multi_hot(label_str)\n",
    "    # Add it to the list\n",
    "    all_labels.append(y)\n",
    "\n",
    "# 3. Convert the list of vectors into one big numpy array\n",
    "Y = np.stack(all_labels, axis=0)\n",
    "\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "\n",
    "# Quick label stats\n",
    "pos_per_class = Y.sum(axis=0)\n",
    "print(\"Positives per class:\", dict(zip(LABELS, pos_per_class.astype(int))))\n",
    "\n",
    "# Patient-level split to avoid leakage\n",
    "df[\"Patient ID\"] = df[\"Patient ID\"].astype(str)\n",
    "bucket = df[\"Patient ID\"].apply(lambda x: hash(x) % 10)  # 0..9\n",
    "train_df = df[bucket < 8].reset_index(drop=True)\n",
    "val_df   = df[bucket == 8].reset_index(drop=True)\n",
    "test_df  = df[bucket == 9].reset_index(drop=True)\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2a974c9-0df4-4f2b-a5f2-279395508567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc7981-0cbb-4af3-9f13-f9adab142ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
