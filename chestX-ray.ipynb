{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c41317d-6ddc-4981-ad21-642cfdce4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /home/matinm/chest X-ray/.git/\n"
     ]
    }
   ],
   "source": [
    "!git init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96ee1714-b491-466d-b69f-e317550981d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: remote origin already exists.\n"
     ]
    }
   ],
   "source": [
    "!git remote add origin https://github.com/MatinM-96/Chest-X-ray.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dca9ae7-db00-4f22-bd7c-c2cc191afaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4468acd-b97b-4f47-8036-59de43990af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter cell, the leading \"!\" runs a shell command\n",
    "!pip -q install kaggle\n",
    "\n",
    "# Upload your Kaggle API key (kaggle.json) to the notebook, or paste below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0300f9e2-c218-47ca-b8f3-6591cfc5473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'kaggle.json': No such file or directory\n",
      "-rw------- 1 matinm users 64 Aug 18 09:12 /home/matinm/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -lah ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1a8bdfb-610c-4861-9a8b-64a4d5f67baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d0bbd3-89d5-4968-a3a4-f7cf9e1185b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'kaggle.json': No such file or directory\n",
      "ls: cannot access '/home/matinm/.kaggle/kaggle.json#': No such file or directory\n",
      "ls: cannot access 'Install': No such file or directory\n",
      "ls: cannot access 'dependencies': No such file or directory\n",
      "ls: cannot access 'as': No such file or directory\n",
      "ls: cannot access 'needed:': No such file or directory\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls -lah ~/.kaggle/kaggle.json# Install dependencies as needed:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# pip install kagglehub[pandas-datasets]\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KaggleDatasetAdapter\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set the path to the file you'd like to load\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!ls -lah ~/.kaggle/kaggle.json# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0370c94b-9ec8-4aa8-8634-c51ef825f6fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kagglehub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Install dependencies as needed:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pip install kagglehub[pandas-datasets]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkagglehub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KaggleDatasetAdapter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set the path to the file you'd like to load\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kagglehub'"
     ]
    }
   ],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b5000-a3b3-4ffb-82c6-2558750a85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d265da-8bca-444a-aa71-7874a0123a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies as needed:\n",
    "# pip install kagglehub[pandas-datasets]\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Set the path to the file you'd like to load\n",
    "file_path = \"\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"nih-chest-xrays/data\",\n",
    "  file_path,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "print(\"First 5 records:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e6beb-1f21-4261-9848-d91beb67adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "with open(\"./kaggle.json\", \"r\") as f:   # change to \"./kaggle.json\" if it's beside the notebook\n",
    "    creds = json.load(f)\n",
    "os.environ[\"KAGGLE_USERNAME\"] = creds[\"username\"]\n",
    "os.environ[\"KAGGLE_KEY\"] = creds[\"key\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a97a4c3e-e886-4174-8501-0024d230ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_152/2672883383.py:10: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
      "Shape of Y: (112120, 14)\n",
      "Positives per class: {'Atelectasis': 11559, 'Cardiomegaly': 2776, 'Effusion': 13317, 'Infiltration': 19894, 'Mass': 5782, 'Nodule': 6331, 'Pneumonia': 1431, 'Pneumothorax': 5302, 'Consolidation': 4667, 'Edema': 2303, 'Emphysema': 2516, 'Fibrosis': 1686, 'Pleural_Thickening': 3385, 'Hernia': 227}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/usr/local/lib/python3.10/dist-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/usr/local/lib/python3.10/dist-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_152/2672883383.py\", line 131, in __getitem__\n    img = Image.open(img_path).convert(\"RGB\")\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3247, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'chest-xray/Images/00020751_002.png'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 196\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    195\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m track(train_dl, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    197\u001b[0m         xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(DEVICE, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), yb\u001b[38;5;241m.\u001b[39mto(DEVICE, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    198\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rich/progress.py:168\u001b[0m, in \u001b[0;36mtrack\u001b[0;34m(sequence, description, total, auto_refresh, console, transient, get_time, refresh_per_second, style, complete_style, finished_style, pulse_style, update_period, disable, show_speed)\u001b[0m\n\u001b[1;32m    157\u001b[0m progress \u001b[38;5;241m=\u001b[39m Progress(\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39mcolumns,\n\u001b[1;32m    159\u001b[0m     auto_refresh\u001b[38;5;241m=\u001b[39mauto_refresh,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     disable\u001b[38;5;241m=\u001b[39mdisable,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mtrack(\n\u001b[1;32m    169\u001b[0m         sequence, total\u001b[38;5;241m=\u001b[39mtotal, description\u001b[38;5;241m=\u001b[39mdescription, update_period\u001b[38;5;241m=\u001b[39mupdate_period\n\u001b[1;32m    170\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/rich/progress.py:1209\u001b[0m, in \u001b[0;36mProgress.track\u001b[0;34m(self, sequence, total, task_id, description, update_period)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlive\u001b[38;5;241m.\u001b[39mauto_refresh:\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _TrackThread(\u001b[38;5;28mself\u001b[39m, task_id, update_period) \u001b[38;5;28;01mas\u001b[39;00m track_thread:\n\u001b[0;32m-> 1209\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m sequence:\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m value\n\u001b[1;32m   1211\u001b[0m             track_thread\u001b[38;5;241m.\u001b[39mcompleted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py:699\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_152/2672883383.py\", line 131, in __getitem__\n    img = Image.open(img_path).convert(\"RGB\")\n  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3247, in open\n    fp = builtins.open(filename, \"rb\")\nFileNotFoundError: [Errno 2] No such file or directory: 'chest-xray/Images/00020751_002.png'\n"
     ]
    }
   ],
   "source": [
    "# pip install kagglehub[pandas-datasets] pandas\n",
    "\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Pick a file from the dataset to read directly into pandas:\n",
    "file_path = \"Data_Entry_2017.csv\"   # NIH Chest X-rays: labels/metadata CSV\n",
    "\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"nih-chest-xrays/data\",\n",
    "    file_path,\n",
    "    pandas_kwargs={\"low_memory\": False}  # optional pandas args\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# NIH canonical 14 labels\n",
    "LABELS = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','Nodule',\n",
    "    'Pneumonia','Pneumothorax','Consolidation','Edema','Emphysema',\n",
    "    'Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "\n",
    "\n",
    "# Convert “Finding Labels” to multi-hot vectors\n",
    "def to_multi_hot(lbl_str):\n",
    "    y = np.zeros(len(LABELS), dtype=np.float32)\n",
    "    if isinstance(lbl_str, str) and lbl_str != \"No Finding\":\n",
    "        for t in lbl_str.split(\"|\"):\n",
    "            if t in LABELS:\n",
    "                y[LABELS.index(t)] = 1.0\n",
    "    return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. Make an empty list\n",
    "all_labels = []\n",
    "\n",
    "# 2. Loop over each row in the DataFrame\n",
    "for label_str in df[\"Finding Labels\"].astype(str):\n",
    "    # Convert string like \"Cardiomegaly|Effusion\" to a multi-hot vector\n",
    "    y = to_multi_hot(label_str)\n",
    "    # Add it to the list\n",
    "    all_labels.append(y)\n",
    "\n",
    "# 3. Convert the list of vectors into one big numpy array\n",
    "Y = np.stack(all_labels, axis=0)\n",
    "\n",
    "print(\"Shape of Y:\", Y.shape)\n",
    "\n",
    "\n",
    "# Quick label stats\n",
    "pos_per_class = Y.sum(axis=0)\n",
    "print(\"Positives per class:\", dict(zip(LABELS, pos_per_class.astype(int))))\n",
    "\n",
    "# Patient-level split to avoid leakage\n",
    "df[\"Patient ID\"] = df[\"Patient ID\"].astype(str)\n",
    "bucket = df[\"Patient ID\"].apply(lambda x: hash(x) % 10)  # 0..9\n",
    "train_df = df[bucket < 8].reset_index(drop=True)\n",
    "val_df   = df[bucket == 8].reset_index(drop=True)\n",
    "test_df  = df[bucket == 9].reset_index(drop=True)\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)\n",
    "\n",
    "\n",
    "#how to downalod the data \n",
    "\n",
    "# import kagglehub\n",
    "\n",
    "# path = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n",
    "# print(\"Dataset downloaded to:\", path)\n",
    "\n",
    "# IMAGES_ROOT = f\"{path}/images\"\n",
    "\n",
    "\n",
    "# !pip install kagglehub\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# TODO: set this to where images are accessible in your environment.\n",
    "# For Kaggle Notebooks, inspect the dataset sidebar to confirm the path.\n",
    "\n",
    "\n",
    "\n",
    "imagePath =  \"./chest-xray/images\"\n",
    "\n",
    "IMG_SIZE = 384\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE*1.1)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def row_to_multi_hot(row):\n",
    "    return torch.tensor(to_multi_hot(row[\"Finding Labels\"]), dtype=torch.float32)\n",
    "\n",
    "class ChestXray(Dataset):\n",
    "    def __init__(self, df, root, tfm):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.root = root\n",
    "        self.tfm = tfm\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        img_path = os.path.join(self.root, r[\"Image Index\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.tfm(img)\n",
    "        y = row_to_multi_hot(r)\n",
    "        return x, y\n",
    "\n",
    "train_ds = ChestXray(train_df, IMAGES_ROOT, train_tfms)\n",
    "val_ds   = ChestXray(val_df, IMAGES_ROOT, val_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torchvision import models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from rich.progress import track\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Model\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features, len(LABELS))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Loss with optional class weights (handles imbalance)\n",
    "# pos_weight = (N - pos) / pos  per class\n",
    "N = len(train_df)\n",
    "pos = torch.tensor([(train_df[\"Finding Labels\"].astype(str).str.contains(l)).sum() for l in LABELS], dtype=torch.float32)\n",
    "pos = torch.clamp(pos, min=1.0)\n",
    "pos_weight = (N - pos) / pos\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(DEVICE))\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            p = torch.sigmoid(model(xb))\n",
    "            ys.append(yb.cpu()); ps.append(p.cpu())\n",
    "    ys = torch.cat(ys, 0).numpy()\n",
    "    ps = torch.cat(ps, 0).numpy()\n",
    "    per_cls = []\n",
    "    for c in range(len(LABELS)):\n",
    "        try:\n",
    "            per_cls.append(roc_auc_score(ys[:,c], ps[:,c]))\n",
    "        except ValueError:\n",
    "            per_cls.append(float(\"nan\"))\n",
    "    return float(np.nanmean(per_cls)), dict(zip(LABELS, per_cls))\n",
    "\n",
    "best_auc, best_path = -1.0, \"densenet121_best.pt\"\n",
    "EPOCHS = 10\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb, yb in track(train_dl, description=f\"Epoch {ep}/{EPOCHS}\"):\n",
    "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "    scheduler.step()\n",
    "\n",
    "    mean_auc, per_cls = evaluate(model, val_dl)\n",
    "    print(f\"Val mean AUROC: {mean_auc:.4f}\")\n",
    "    if mean_auc > best_auc:\n",
    "        best_auc = mean_auc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"Saved new best to {best_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d47f88d-34cd-4295-b0c1-882a7c2b155e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 00000001_000.png\n",
      "Missing: 00000001_001.png\n",
      "Missing: 00000001_002.png\n",
      "Missing: 00000002_000.png\n",
      "Missing: 00000003_000.png\n",
      "Missing: 00000003_001.png\n",
      "Missing: 00000003_002.png\n",
      "Missing: 00000003_003.png\n",
      "Missing: 00000003_004.png\n",
      "Missing: 00000003_005.png\n",
      "Missing: 00000003_006.png\n",
      "Missing: 00000003_007.png\n",
      "Missing: 00000004_000.png\n",
      "Missing: 00000005_000.png\n",
      "Missing: 00000005_001.png\n",
      "Missing: 00000005_002.png\n",
      "Missing: 00000005_003.png\n",
      "Missing: 00000005_004.png\n",
      "Missing: 00000005_005.png\n",
      "Missing: 00000005_006.png\n",
      "Missing among first 20: 20\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Folder not found: ./chestX-ray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m         missing \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing among first 20:\u001b[39m\u001b[38;5;124m\"\u001b[39m, missing)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Path(IMAGES_ROOT)\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFolder not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIMAGES_ROOT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (Optional but helpful for any occasional corrupted file)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFile\n",
      "\u001b[0;31mAssertionError\u001b[0m: Folder not found: ./chestX-ray"
     ]
    }
   ],
   "source": [
    "# ---- 1) Point to your existing images ----\n",
    "# Example paths — change to YOUR real folder:\n",
    "# IMAGES_ROOT = \"/data/nih/images\"\n",
    "# IMAGES_ROOT = \"/srv/datasets/NIH-ChestXray/images\"\n",
    "  # <-- put your real path\n",
    "imagePath = \"./chest-xray\"\n",
    "\n",
    "\n",
    "\n",
    "# Quick sanity check (prints a few that must exist)\n",
    "from pathlib import Path\n",
    "missing = 0\n",
    "for name in df[\"Image Index\"].head(20):\n",
    "    if not Path(IMAGES_ROOT, name).exists():\n",
    "        print(\"Missing:\", name)\n",
    "        missing += 1\n",
    "print(\"Missing among first 20:\", missing)\n",
    "assert Path(IMAGES_ROOT).exists(), f\"Folder not found: {IMAGES_ROOT}\"\n",
    "\n",
    "# (Optional but helpful for any occasional corrupted file)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c41ca09-3ef4-4927-8ecb-8d6493890521",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"./chest X-ray/images\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12c3e334-dd1e-493e-8968-70644a0f5221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./chest-xray/images'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a48385f2-fb8e-43ae-9983-e0e562722170",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chestX-ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchestX-ray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chestX-ray'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"chestX-ray\")[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef7e0d97-9c89-48f8-b479-bdc86126682b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chestX-ray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m IMAGES_ROOT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chestX-ray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchestX-ray\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m10\u001b[39m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chestX-ray'"
     ]
    }
   ],
   "source": [
    "IMAGES_ROOT = \"./chestX-ray\"\n",
    "import os\n",
    "print(os.listdir(\"chestX-ray\")[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84aab461-000c-4c50-922a-c43c65a4540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images_007', 'ARXIV_V5_CHESTXRAY.pdf', 'images_002', 'images_006', 'test_list.txt', 'Data_Entry_2017.csv', 'images_003', 'images_009', 'BBox_List_2017.csv', 'images_012']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"chest-xray\")[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "985ed23a-c850-42db-8df0-a0aa9d79eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "df shape: (112120, 12)\n",
      "Y shape: (112120, 14)\n",
      "Positives per class: {'Atelectasis': 11559, 'Cardiomegaly': 2776, 'Effusion': 13317, 'Infiltration': 19894, 'Mass': 5782, 'Nodule': 6331, 'Pneumonia': 1431, 'Pneumothorax': 5302, 'Consolidation': 4667, 'Edema': 2303, 'Emphysema': 2516, 'Fibrosis': 1686, 'Pleural_Thickening': 3385, 'Hernia': 227}\n",
      "split sizes: 89522 11292 11306\n",
      "Indexed files: 112120\n",
      "Missing among first 20: 0\n",
      "Splits: 89522 11292 11306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 2798/2798 [21:34<00:00,  2.16it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7246 | microF1=0.1520 | macroF1=0.1484 | train_loss=1.1735\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 2798/2798 [18:12<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7730 | microF1=0.1947 | macroF1=0.1758 | train_loss=1.0931\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 2798/2798 [18:23<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7949 | microF1=0.2105 | macroF1=0.1867 | train_loss=1.0412\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 2798/2798 [18:06<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8115 | microF1=0.2264 | macroF1=0.1962 | train_loss=0.9937\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 2798/2798 [18:45<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8182 | microF1=0.2383 | macroF1=0.2127 | train_loss=0.9536\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  59%|█████▊    | 1641/2798 [11:06<08:15,  2.33it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Epoch 8/10: 100%|██████████| 2798/2798 [18:38<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8386 | microF1=0.2566 | macroF1=0.2331 | train_loss=0.8449\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 2798/2798 [18:20<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8414 | microF1=0.2712 | macroF1=0.2453 | train_loss=0.8129\n",
      "✅ Saved new best to densenet121_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 2798/2798 [18:20<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8439 | microF1=0.2697 | macroF1=0.2434 | train_loss=0.7995\n",
      "✅ Saved new best to densenet121_best.pt\n",
      "[TEST] mean AUROC=0.8409 | microF1=0.2799 | macroF1=0.2486\n",
      "Per-class AUROC: {'Atelectasis': 0.7849813395895311, 'Cardiomegaly': 0.9434074220584963, 'Effusion': 0.8849623733879217, 'Infiltration': 0.7067924720462269, 'Mass': 0.8391730482107597, 'Nodule': 0.7907630876697277, 'Pneumonia': 0.7502949175725163, 'Pneumothorax': 0.8719545007529546, 'Consolidation': 0.8000228201090801, 'Edema': 0.8950595394746327, 'Emphysema': 0.9474297911590529, 'Fibrosis': 0.8047051601080092, 'Pleural_Thickening': 0.8111228237080977, 'Hernia': 0.9425364618342686}\n"
     ]
    }
   ],
   "source": [
    "# ========================== SETUP ==========================\n",
    "# pip installs (uncomment if needed)\n",
    "# !pip install -q kagglehub pandas torch torchvision scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ========================== 1) LOAD CSV ==========================\n",
    "# If you already loaded df with kagglehub in earlier cells, keep it.\n",
    "# Otherwise, assuming the CSV sits next to your image folders (per screenshot):\n",
    "csv_path = Path(\"./chest-xray/Data_Entry_2017.csv\")\n",
    "assert csv_path.exists(), f\"CSV not found at: {csv_path}\"\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"df shape:\", df.shape)\n",
    "\n",
    "# ========================== 2) LABELS + MULTI-HOT ==========================\n",
    "LABELS = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','Nodule',\n",
    "    'Pneumonia','Pneumothorax','Consolidation','Edema','Emphysema',\n",
    "    'Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "\n",
    "def to_multi_hot(lbl_str):\n",
    "    y = np.zeros(len(LABELS), dtype=np.float32)\n",
    "    if isinstance(lbl_str, str) and lbl_str != \"No Finding\":\n",
    "        for t in lbl_str.split(\"|\"):\n",
    "            if t in LABELS:\n",
    "                y[LABELS.index(t)] = 1.0\n",
    "    return y\n",
    "\n",
    "# build Y (aligned to df rows)\n",
    "Y = np.stack([to_multi_hot(s) for s in df[\"Finding Labels\"].astype(str)], axis=0)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "\n",
    "# simple stats\n",
    "pos_per_class = Y.sum(axis=0)\n",
    "print(\"Positives per class:\", dict(zip(LABELS, pos_per_class.astype(int))))\n",
    "\n",
    "# ========================== 3) PATIENT-LEVEL SPLIT ==========================\n",
    "df[\"Patient ID\"] = df[\"Patient ID\"].astype(str)\n",
    "bucket = df[\"Patient ID\"].apply(lambda x: hash(x) % 10)  # 0..9\n",
    "train_df = df[bucket < 8].reset_index(drop=True)\n",
    "val_df   = df[bucket == 8].reset_index(drop=True)\n",
    "test_df  = df[bucket == 9].reset_index(drop=True)\n",
    "print(\"split sizes:\", len(train_df), len(val_df), len(test_df))\n",
    "\n",
    "# ========================== 4) INDEX FILES ACROSS SUBFOLDERS ==========================\n",
    "# Your screenshot: chestX-ray/chest-xray/images_001..images_012\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# Set this to the parent that directly contains images_001, images_002, ...\n",
    "# Example 1 (from your screenshots):\n",
    "# BASE = Path(\"./chestX-ray/chest-xray\")\n",
    "# Example 2 (from your absolute path snippet):\n",
    "BASE = Path(\"./chest-xray\")   # <-- change if needed\n",
    "\n",
    "assert BASE.exists(), f\"Base not found: {BASE}\"\n",
    "\n",
    "# Build: filename -> full path, handling the extra '/images/' level\n",
    "name_to_path = {}\n",
    "for p in BASE.glob(\"images_*/images/*.png\"):\n",
    "    name_to_path[p.name] = str(p)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Indexed files:\", len(name_to_path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# quick sanity: first 20 filenames should all be found\n",
    "first20 = df[\"Image Index\"].head(20).tolist()\n",
    "missing20 = [n for n in first20 if n not in name_to_path]\n",
    "print(\"Missing among first 20:\", len(missing20))\n",
    "if missing20:\n",
    "    print(\"Example missing:\", missing20[:5])\n",
    "\n",
    "# ========================== 5) DATASET / LOADERS ==========================\n",
    "IMG_SIZE = 384\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE*1.1)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def row_to_multi_hot(row):\n",
    "    return torch.tensor(to_multi_hot(row[\"Finding Labels\"]), dtype=torch.float32)\n",
    "\n",
    "class ChestXray(Dataset):\n",
    "    def __init__(self, df, index_map, tfm):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.idx = index_map\n",
    "        self.tfm = tfm\n",
    "    def __len__(self): \n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        fname = r[\"Image Index\"]\n",
    "        img_path = self.idx.get(fname)\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"Image not indexed: {fname}\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.tfm(img)\n",
    "        y = row_to_multi_hot(r)\n",
    "        return x, y\n",
    "\n",
    "train_ds = ChestXray(train_df, name_to_path, train_tfms)\n",
    "val_ds   = ChestXray(val_df,   name_to_path, val_tfms)\n",
    "test_ds  = ChestXray(test_df,  name_to_path, val_tfms)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2  # set 0 if you see multiprocessing issues\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Splits:\", len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "# ========================== 6) MODEL ==========================\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features, len(LABELS))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ========================== 7) LOSS (pos_weight from TRAIN) ==========================\n",
    "train_multi = np.vstack(train_df[\"Finding Labels\"].astype(str).map(\n",
    "    lambda s: np.array(to_multi_hot(s), dtype=np.float32)\n",
    ").values)\n",
    "pos = train_multi.sum(axis=0)  # per-class positives in TRAIN\n",
    "N = len(train_df)\n",
    "pos = np.clip(pos, 1.0, None)\n",
    "pos_weight = torch.tensor((N - pos) / pos, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
    "\n",
    "# ========================== 8) EVAL FUNCTION ==========================\n",
    "def evaluate(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            p = torch.sigmoid(model(xb))\n",
    "            ys.append(yb.cpu()); ps.append(p.cpu())\n",
    "    ys = torch.cat(ys, 0).numpy()\n",
    "    ps = torch.cat(ps, 0).numpy()\n",
    "\n",
    "    # AUROC per class\n",
    "    aurocs = []\n",
    "    for c in range(len(LABELS)):\n",
    "        y_c, p_c = ys[:, c], ps[:, c]\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(y_c, p_c))\n",
    "        except ValueError:\n",
    "            aurocs.append(np.nan)\n",
    "    mean_auc = float(np.nanmean(aurocs))\n",
    "\n",
    "    # F1s at threshold\n",
    "    preds = (ps >= threshold).astype(\"int32\")\n",
    "    micro_f1 = f1_score(ys, preds, average=\"micro\", zero_division=0)\n",
    "    macro_f1 = f1_score(ys, preds, average=\"macro\", zero_division=0)\n",
    "    return mean_auc, dict(zip(LABELS, aurocs)), micro_f1, macro_f1\n",
    "\n",
    "# ========================== 9) TRAIN ==========================\n",
    "EPOCHS = 10\n",
    "best_auc, best_path = -1.0, \"densenet121_best.pt\"\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in tqdm(train_dl, desc=f\"Epoch {ep}/{EPOCHS}\"):\n",
    "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        running += loss.item() * xb.size(0)\n",
    "    scheduler.step()\n",
    "    train_loss = running / len(train_ds)\n",
    "\n",
    "    val_mean_auc, _, val_micro_f1, val_macro_f1 = evaluate(model, val_dl)\n",
    "    print(f\"[Val] mean AUROC={val_mean_auc:.4f} | microF1={val_micro_f1:.4f} | macroF1={val_macro_f1:.4f} | train_loss={train_loss:.4f}\")\n",
    "    if val_mean_auc > best_auc:\n",
    "        best_auc = val_mean_auc\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "        print(f\"✅ Saved new best to {best_path}\")\n",
    "\n",
    "# ========================== 10) TEST ==========================\n",
    "if Path(best_path).exists():\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "\n",
    "test_mean_auc, test_per_cls, test_micro_f1, test_macro_f1 = evaluate(model, test_dl)\n",
    "print(f\"[TEST] mean AUROC={test_mean_auc:.4f} | microF1={test_micro_f1:.4f} | macroF1={test_macro_f1:.4f}\")\n",
    "print(\"Per-class AUROC:\", {k: (None if np.isnan(v) else float(v)) for k, v in test_per_cls.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "923ca284-a2ea-453f-b23e-8833b805a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "df shape: (112120, 12)\n",
      "Y shape: (112120, 14)\n",
      "Positives per class: {'Atelectasis': 11559, 'Cardiomegaly': 2776, 'Effusion': 13317, 'Infiltration': 19894, 'Mass': 5782, 'Nodule': 6331, 'Pneumonia': 1431, 'Pneumothorax': 5302, 'Consolidation': 4667, 'Edema': 2303, 'Emphysema': 2516, 'Fibrosis': 1686, 'Pleural_Thickening': 3385, 'Hernia': 227}\n",
      "Split sizes -> Train: 89522 Val: 11292 Test: 11306\n",
      "Indexed files: 112120\n",
      "Missing among first 20: 0\n",
      "DL sizes -> 89522 11292 11306\n",
      " Starting fresh training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 2798/2798 [18:33<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7329 | microF1=0.1702 | macroF1=0.1597 | train_loss=1.2056\n",
      " Saved last: densenet121_last.pt (epoch=1)\n",
      " Saved BEST: densenet121_best.pt (epoch=1, best_auc=0.7329)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 2798/2798 [18:20<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7633 | microF1=0.2145 | macroF1=0.1831 | train_loss=1.1214\n",
      " Saved last: densenet121_last.pt (epoch=2)\n",
      " Saved BEST: densenet121_best.pt (epoch=2, best_auc=0.7633)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 2798/2798 [18:22<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.7850 | microF1=0.1850 | macroF1=0.1783 | train_loss=1.0668\n",
      " Saved last: densenet121_last.pt (epoch=3)\n",
      " Saved BEST: densenet121_best.pt (epoch=3, best_auc=0.7850)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 2798/2798 [18:17<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8019 | microF1=0.2071 | macroF1=0.1952 | train_loss=1.0184\n",
      " Saved last: densenet121_last.pt (epoch=4)\n",
      " Saved BEST: densenet121_best.pt (epoch=4, best_auc=0.8019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 2798/2798 [18:18<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8118 | microF1=0.2029 | macroF1=0.1879 | train_loss=0.9770\n",
      " Saved last: densenet121_last.pt (epoch=5)\n",
      " Saved BEST: densenet121_best.pt (epoch=5, best_auc=0.8118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 2798/2798 [18:25<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8232 | microF1=0.2528 | macroF1=0.2174 | train_loss=0.9343\n",
      " Saved last: densenet121_last.pt (epoch=6)\n",
      " Saved BEST: densenet121_best.pt (epoch=6, best_auc=0.8232)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 2798/2798 [18:22<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8301 | microF1=0.2436 | macroF1=0.2230 | train_loss=0.9017\n",
      " Saved last: densenet121_last.pt (epoch=7)\n",
      " Saved BEST: densenet121_best.pt (epoch=7, best_auc=0.8301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 2798/2798 [18:15<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8334 | microF1=0.2470 | macroF1=0.2237 | train_loss=0.8658\n",
      " Saved last: densenet121_last.pt (epoch=8)\n",
      " Saved BEST: densenet121_best.pt (epoch=8, best_auc=0.8334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 2798/2798 [18:25<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8385 | microF1=0.2567 | macroF1=0.2317 | train_loss=0.8409\n",
      " Saved last: densenet121_last.pt (epoch=9)\n",
      " Saved BEST: densenet121_best.pt (epoch=9, best_auc=0.8385)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 2798/2798 [18:18<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] mean AUROC=0.8389 | microF1=0.2577 | macroF1=0.2335 | train_loss=0.8290\n",
      " Saved last: densenet121_last.pt (epoch=10)\n",
      " Saved BEST: densenet121_best.pt (epoch=10, best_auc=0.8389)\n",
      "✅ Loaded BEST from epoch 10 (best_auc=0.8389)\n",
      "[TEST] mean AUROC=0.8400 | microF1=0.2718 | macroF1=0.2427\n",
      "Per-class AUROC: {'Atelectasis': 0.7831616003470198, 'Cardiomegaly': 0.941590394013565, 'Effusion': 0.8831769429188057, 'Infiltration': 0.7043728759956689, 'Mass': 0.838729952319029, 'Nodule': 0.7635560244637238, 'Pneumonia': 0.7530193523358116, 'Pneumothorax': 0.8707031660967021, 'Consolidation': 0.8014594410594617, 'Edema': 0.896692123277375, 'Emphysema': 0.9405880088210847, 'Fibrosis': 0.8056480628831213, 'Pleural_Thickening': 0.8123890394150828, 'Hernia': 0.965578152600397}\n"
     ]
    }
   ],
   "source": [
    "# ========================== SETUP ==========================\n",
    "# !pip install -q pandas torch torchvision scikit-learn tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# ========================== 1) PATHS ==========================\n",
    "CSV_PATH = Path(\"./chest-xray/Data_Entry_2017.csv\")    # <- change if needed\n",
    "BASE     = Path(\"./chest-xray\")                        # contains images_001, images_002, ...\n",
    "assert CSV_PATH.exists(), f\"CSV not found: {CSV_PATH}\"\n",
    "assert BASE.exists(), f\"Base images folder not found: {BASE}\"\n",
    "\n",
    "# ========================== 2) LOAD CSV ==========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"df shape:\", df.shape)\n",
    "\n",
    "# ========================== 3) LABELS + MULTI-HOT ==========================\n",
    "LABELS = [\n",
    "    'Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','Nodule',\n",
    "    'Pneumonia','Pneumothorax','Consolidation','Edema','Emphysema',\n",
    "    'Fibrosis','Pleural_Thickening','Hernia'\n",
    "]\n",
    "\n",
    "def to_multi_hot(lbl_str: str):\n",
    "    y = np.zeros(len(LABELS), dtype=np.float32)\n",
    "    if isinstance(lbl_str, str) and lbl_str != \"No Finding\":\n",
    "        for t in lbl_str.split(\"|\"):\n",
    "            if t in LABELS:\n",
    "                y[LABELS.index(t)] = 1.0\n",
    "    return y\n",
    "\n",
    "Y = np.stack([to_multi_hot(s) for s in df[\"Finding Labels\"].astype(str)], axis=0)\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\"Positives per class:\", dict(zip(LABELS, Y.sum(axis=0).astype(int))))\n",
    "\n",
    "# ========================== 4) PATIENT-LEVEL SPLIT (80/10/10) ==========================\n",
    "df[\"Patient ID\"] = df[\"Patient ID\"].astype(str)\n",
    "bucket = df[\"Patient ID\"].apply(lambda x: hash(x) % 10)  # 0..9\n",
    "train_df = df[bucket < 8].reset_index(drop=True)\n",
    "val_df   = df[bucket == 8].reset_index(drop=True)\n",
    "test_df  = df[bucket == 9].reset_index(drop=True)\n",
    "print(\"Split sizes -> Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
    "\n",
    "# ========================== 5) INDEX FILES ACROSS SHARDS ==========================\n",
    "# Your layout: BASE / images_XXX / images / *.png\n",
    "name_to_path = {}\n",
    "for p in BASE.glob(\"images_*/images/*.png\"):\n",
    "    name_to_path[p.name] = str(p)\n",
    "\n",
    "print(\"Indexed files:\", len(name_to_path))\n",
    "first20 = df[\"Image Index\"].head(20).tolist()\n",
    "missing20 = [n for n in first20 if n not in name_to_path]\n",
    "print(\"Missing among first 20:\", len(missing20))\n",
    "if missing20:\n",
    "    print(\"Example missing:\", missing20[:5])\n",
    "\n",
    "# ========================== 6) DATASET / DATALOADERS ==========================\n",
    "IMG_SIZE = 384\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize(int(IMG_SIZE*1.1)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
    "])\n",
    "\n",
    "def row_to_multi_hot_tensor(row):\n",
    "    return torch.tensor(to_multi_hot(row[\"Finding Labels\"]), dtype=torch.float32)\n",
    "\n",
    "class ChestXray(Dataset):\n",
    "    def __init__(self, df, index_map, tfm):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.idx = index_map\n",
    "        self.tfm = tfm\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        r = self.df.iloc[i]\n",
    "        fname = r[\"Image Index\"]\n",
    "        img_path = self.idx.get(fname)\n",
    "        if img_path is None:\n",
    "            raise FileNotFoundError(f\"Image not indexed: {fname}\")\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = self.tfm(img)\n",
    "        y = row_to_multi_hot_tensor(r)\n",
    "        return x, y\n",
    "\n",
    "train_ds = ChestXray(train_df, name_to_path, train_tfms)\n",
    "val_ds   = ChestXray(val_df,   name_to_path, val_tfms)\n",
    "test_ds  = ChestXray(test_df,  name_to_path, val_tfms)\n",
    "\n",
    "BATCH_SIZE  = 32\n",
    "NUM_WORKERS = 2  # set 0 if multiprocessing issues\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"DL sizes ->\", len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "# ========================== 7) MODEL ==========================\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features, len(LABELS))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# ========================== 8) LOSS (pos_weight from TRAIN) ==========================\n",
    "train_multi = np.vstack(train_df[\"Finding Labels\"].astype(str).map(\n",
    "    lambda s: np.array(to_multi_hot(s), dtype=np.float32)\n",
    ").values)\n",
    "pos = train_multi.sum(axis=0)    # per-class positives in TRAIN\n",
    "N = len(train_df)\n",
    "pos = np.clip(pos, 1.0, None)    # avoid div-by-zero\n",
    "pos_weight = torch.tensor((N - pos) / pos, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "# ========================== 9) EVALUATION ==========================\n",
    "def evaluate(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            p = torch.sigmoid(model(xb))\n",
    "            ys.append(yb.cpu()); ps.append(p.cpu())\n",
    "    ys = torch.cat(ys, 0).numpy()\n",
    "    ps = torch.cat(ps, 0).numpy()\n",
    "\n",
    "    # AUROC per class\n",
    "    aurocs = []\n",
    "    for c in range(len(LABELS)):\n",
    "        y_c, p_c = ys[:, c], ps[:, c]\n",
    "        try:\n",
    "            aurocs.append(roc_auc_score(y_c, p_c))\n",
    "        except ValueError:\n",
    "            aurocs.append(np.nan)\n",
    "    mean_auc = float(np.nanmean(aurocs))\n",
    "\n",
    "    # F1 at fixed threshold (reference only)\n",
    "    preds = (ps >= threshold).astype(\"int32\")\n",
    "    micro_f1 = f1_score(ys, preds, average=\"micro\", zero_division=0)\n",
    "    macro_f1 = f1_score(ys, preds, average=\"macro\", zero_division=0)\n",
    "    return mean_auc, dict(zip(LABELS, aurocs)), micro_f1, macro_f1\n",
    "\n",
    "# ========================== 10) TRAIN with CHECKPOINTS ==========================\n",
    "best_path = \"densenet121_best.pt\"\n",
    "last_path = \"densenet121_last.pt\"\n",
    "RESUME    = True\n",
    "EPOCHS    = 10\n",
    "\n",
    "def make_ckpt(epoch, best_auc):\n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"best_auc\": best_auc,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": optimizer.state_dict(),\n",
    "        \"scheduler_state\": scheduler.state_dict(),\n",
    "        \"scaler_state\": scaler.state_dict(),\n",
    "    }\n",
    "\n",
    "def save_last(epoch, best_auc):\n",
    "    torch.save(make_ckpt(epoch, best_auc), last_path)\n",
    "    print(f\" Saved last: {last_path} (epoch={epoch})\")\n",
    "\n",
    "def save_best(epoch, best_auc):\n",
    "    torch.save(make_ckpt(epoch, best_auc), best_path)\n",
    "    print(f\" Saved BEST: {best_path} (epoch={epoch}, best_auc={best_auc:.4f})\")\n",
    "\n",
    "# Resume\n",
    "start_epoch = 1\n",
    "best_auc = -1.0\n",
    "if RESUME and os.path.exists(last_path):\n",
    "    ckpt = torch.load(last_path, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "    scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n",
    "    scaler.load_state_dict(ckpt[\"scaler_state\"])\n",
    "    start_epoch = ckpt[\"epoch\"] + 1\n",
    "    best_auc    = ckpt.get(\"best_auc\", best_auc)\n",
    "    print(f\"🔁 Resuming from epoch {start_epoch} (best_auc={best_auc:.4f})\")\n",
    "else:\n",
    "    print(\" Starting fresh training\")\n",
    "\n",
    "# Loop\n",
    "for ep in range(start_epoch, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in tqdm(train_dl, desc=f\"Epoch {ep}/{EPOCHS}\"):\n",
    "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer); scaler.update()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / len(train_ds)\n",
    "\n",
    "    val_mean_auc, _, val_micro_f1, val_macro_f1 = evaluate(model, val_dl)\n",
    "    print(f\"[Val] mean AUROC={val_mean_auc:.4f} | microF1={val_micro_f1:.4f} | macroF1={val_macro_f1:.4f} | train_loss={train_loss:.4f}\")\n",
    "\n",
    "    # Always save \"last\"\n",
    "    save_last(ep, best_auc)\n",
    "\n",
    "    # Save \"best\" if improved\n",
    "    if val_mean_auc > best_auc:\n",
    "        best_auc = val_mean_auc\n",
    "        save_best(ep, best_auc)\n",
    "\n",
    "# ========================== 11) TEST ==========================\n",
    "if Path(best_path).exists():\n",
    "    ckpt = torch.load(best_path, map_location=DEVICE)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    print(f\"✅ Loaded BEST from epoch {ckpt['epoch']} (best_auc={ckpt['best_auc']:.4f})\")\n",
    "else:\n",
    "    print(\"⚠️ BEST checkpoint not found, using last model weights in memory.\")\n",
    "\n",
    "test_mean_auc, test_per_cls, test_micro_f1, test_macro_f1 = evaluate(model, test_dl)\n",
    "print(f\"[TEST] mean AUROC={test_mean_auc:.4f} | microF1={test_micro_f1:.4f} | macroF1={test_macro_f1:.4f}\")\n",
    "print(\"Per-class AUROC:\", {k: (None if np.isnan(v) else float(v)) for k, v in test_per_cls.items()})\n",
    "\n",
    "# ========================== 12) (Optional) SINGLE-IMAGE PREDICT ==========================\n",
    "@torch.no_grad()\n",
    "def predict_image(img_path, threshold=0.5, top_k=5):\n",
    "    model.eval()\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = val_tfms(img).unsqueeze(0).to(DEVICE)\n",
    "    probs = torch.sigmoid(model(x)).squeeze(0).cpu().numpy()\n",
    "    pred_labels = [LABELS[i] for i, p in enumerate(probs) if p >= threshold]\n",
    "    top_idx = np.argsort(-probs)[:top_k]\n",
    "    top = [(LABELS[i], float(probs[i])) for i in top_idx]\n",
    "    return dict(zip(LABELS, map(float, probs))), pred_labels, top\n",
    "\n",
    "# Example:\n",
    "# img_example = \"/chest-xray/images_001/images/00001335_006.png\"\n",
    "# probs, preds, top5 = predict_image(img_example, threshold=0.5, top_k=5)\n",
    "# print(\"Predicted (>=0.5):\", preds)\n",
    "# print(\"Top-5:\", top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65967a-3c7e-45ee-b42e-3c4ca32f6d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
